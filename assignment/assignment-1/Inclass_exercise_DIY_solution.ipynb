{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Necessary imports that you'd need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a label Encoder for converting Categorical Strings into 0/1 for easier data handling. See documentation here : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load your data file (.csv) below **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/house-votes-84.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the dimensions of your dataframe **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(435, 17)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for missing values below **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Class Name                                  0\nhandicapped-infants                        12\nwater-project-cost-sharing                 48\nadoption-of-the-budget-resolution          11\nphysician-fee-freeze                       11\nel-salvador-aid                            15\nreligious-groups-in-schools                11\nanti-satellite-test-ban                    14\naid-to-nicaraguan-contras                  15\nmx-missile                                 22\nimmigration                                 7\nsynfuels-corporation-cutback               21\neducation-spending                         31\nsuperfund-right-to-sue                     25\ncrime                                      17\nduty-free-exports                          28\nexport-administration-act-south-africa    104\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment 1 : Dropping Missing Values below **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_dropNA = df.dropna(inplace=False)\n",
    "#why are we doing an inplace false?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the dimensions of your dataframe again **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(232, 17)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "df_dropNA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transforming your dataframe using label encoding - converting n/y to 0/1 **\n",
    "hint: use .apply on your dataframe and function as le.fit_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#label encoding - converting n/y to 0/1\n",
    "df_transformed = df_dropNA.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### separating predictors and target columns **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#separating columns for train test split\n",
    "X = df_transformed.drop(columns=['Class Name'])\n",
    "y = df_transformed[['Class Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do a train test split. \n",
    "use https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html \n",
    "\n",
    "keep test_size=0.3 and set random state to 1 as your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 1 - Run NaiveBayes Classifier\n",
    "There are different sub-classifiers that we can use. Choose the appropriate one looking at the socumentation : https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "Train your classifier on training set only, use X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Naive-Bayes Classifier\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "c:\\users\\balav\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#initialize your classifier\n",
    "print(\"Naive-Bayes Classifier\")\n",
    "nb = BernoulliNB()\n",
    "\n",
    "#fit your classifier to training set\n",
    "nb = nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your classifier **\n",
    "\n",
    "refer https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html for precision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#use your classifier to predict on the test Set : X_test, save it to a temporary variable y_pred\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Precision: 0.93\nRecall:  0.91\nF1-score:  0.91\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#compare y_pred with actual targets for your test set(y_test) and calculate precision, recall, f1-score\n",
    "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))\n",
    "#compute recall and f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[37  0]\n [ 6 27]]\n              precision    recall  f1-score   support\n\n           0       0.86      1.00      0.92        37\n           1       1.00      0.82      0.90        33\n\n    accuracy                           0.91        70\n   macro avg       0.93      0.91      0.91        70\nweighted avg       0.93      0.91      0.91        70\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 2 - Run Decision Trees\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Train your classifier on training set only, use X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Decision Tree Classifier\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Decision Tree Classifier\")\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your classifier **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Precision: 0.97\nRecall:  0.97\nF1-score:  0.97\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#y-pred - same as above\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#compare y_pred with actual targets for your test set(y_test) and calculate precision, recall, f1-score\n",
    "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[37  0]\n [ 2 31]]\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97        37\n           1       1.00      0.94      0.97        33\n\n    accuracy                           0.97        70\n   macro avg       0.97      0.97      0.97        70\nweighted avg       0.97      0.97      0.97        70\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment 2 : Treating missing values as a 3rd category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#filling NA with 'x' - a temporaty variable \n",
    "#hint: use fillna\n",
    "\n",
    "df_fillNewCat = df.fillna('x',inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the dimensions of your dataframe again **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(435, 17)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 28
    }
   ],
   "source": [
    "#in this case the dimension of your dataframe should be same as the original one - when your loaded the data 1st\n",
    "df_fillNewCat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transforming your dataframe using label encoding - converting n/y to 0/1 **\n",
    "hint: use .apply on your dataframe and function as le.fit_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_transformed = df_fillNewCat.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### separating predictors and target columns **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = df_transformed.drop(columns=['Class Name'])\n",
    "y = df_transformed[['Class Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do a train test split. \n",
    "use https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html \n",
    "\n",
    "keep test_size=0.3 and set random state to 1 as your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 1 - Run NaiveBayes Classifier\n",
    "There are different sub-classifiers that we can use. Choose the appropriate one looking at the socumentation : https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "Train your classifier on training set only, use X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Naive-Bayes Classifier",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "c:\\users\\balav\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#initialize your classifier\n",
    "print(\"Naive-Bayes Classifier\")\n",
    "nb = BernoulliNB()\n",
    "\n",
    "#fit your classifier to training set\n",
    "nb = nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your classifier **\n",
    "\n",
    "refer https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html for precision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#use your classifier to predict on the test Set : X_test, save it to a temporary variable y_pred\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Precision: 0.88\nRecall:  0.91\nF1-score:  0.89\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#compare y_pred with actual targets for your test set(y_test) and calculate precision, recall, f1-score\n",
    "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))\n",
    "#compute recall and f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78 11]\n",
      " [ 2 40]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.88      0.92        89\n",
      "          1       0.78      0.95      0.86        42\n",
      "\n",
      "avg / total       0.91      0.90      0.90       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 2 - Run Decision Trees\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Train your classifier on training set only, use X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classifier\")\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your classifier **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.93\n",
      "Recall:  0.93\n",
      "F1-score:  0.93\n"
     ]
    }
   ],
   "source": [
    "#y-pred - same as above\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#compare y_pred with actual targets for your test set(y_test) and calculate precision, recall, f1-score\n",
    "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  4]\n",
      " [ 4 38]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        89\n",
      "          1       0.90      0.90      0.90        42\n",
      "\n",
      "avg / total       0.94      0.94      0.94       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment 3 : Replacing missing values with Most Common values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an example of how you can do this - implement it on all the columns that have a missing value\n",
    "#df['crime'] = df['crime'].astype('category')\n",
    "#df['crime'].fillna(df['crime'].mode()[0],inplace=True)\n",
    "\n",
    "df_fillMostFr = pd.DataFrame()\n",
    "for col in df.columns:\n",
    "    df_fillMostFr[col] = df[col].astype('category')\n",
    "    df_fillMostFr[col].fillna(df[col].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the same things that you did before\n",
    "\n",
    "1.Check dimensions\n",
    "2. Transform your data\n",
    "3. Separate Target and predictors\n",
    "4. Do a train test split\n",
    "5. Run and evaluate NaiveBayes and DecisionTree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 17)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "df_fillMostFr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "df_transformed = df_fillMostFr.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "X = df_transformed.drop(columns=['Class Name'])\n",
    "y = df_transformed[['Class Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 1 - Run NaiveBayes Classifier\n",
    "There are different sub-classifiers that we can use. Choose the appropriate one looking at the socumentation : https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "Train your classifier on training set only, use X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#initialize your classifier\n",
    "print(\"Naive-Bayes Classifier\")\n",
    "nb = BernoulliNB()\n",
    "\n",
    "#fit your classifier to training set\n",
    "nb = nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your classifier **\n",
    "\n",
    "refer https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html for precision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use your classifier to predict on the test Set : X_test, save it to a temporary variable y_pred\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.88\n",
      "Recall:  0.91\n",
      "F1-score:  0.89\n"
     ]
    }
   ],
   "source": [
    "#compare y_pred with actual targets for your test set(y_test) and calculate precision, recall, f1-score\n",
    "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))\n",
    "#compute recall and f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79 10]\n",
      " [ 3 39]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.89      0.92        89\n",
      "          1       0.80      0.93      0.86        42\n",
      "\n",
      "avg / total       0.91      0.90      0.90       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 2 - Run Decision Trees\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Train your classifier on training set only, use X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classifier\")\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your classifier **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.95\n",
      "Recall:  0.93\n",
      "F1-score:  0.94\n"
     ]
    }
   ],
   "source": [
    "#y-pred - same as above\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#compare y_pred with actual targets for your test set(y_test) and calculate precision, recall, f1-score\n",
    "print(\"Precision: %0.2f\" %precision_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"Recall:  %0.2f\" %recall_score(y_test, y_pred , average=\"macro\"))\n",
    "print(\"F1-score:  %0.2f\" %f1_score(y_test, y_pred , average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78 11]\n",
      " [ 2 40]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.88      0.92        89\n",
      "          1       0.78      0.95      0.86        42\n",
      "\n",
      "avg / total       0.91      0.90      0.90       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossValidation\n",
    "A great read on this : https://towardsdatascience.com/cross-validation-70289113a072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start with Treatment 1: Dropping missing values\n",
    "#### Repeat these same things that you did before\n",
    "\n",
    "1. Check dimensions\n",
    "2. Transform your data\n",
    "3. Separate Target and predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 17)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name                                  0\n",
       "handicapped-infants                        12\n",
       "water-project-cost-sharing                 48\n",
       "adoption-of-the-budget-resolution          11\n",
       "physician-fee-freeze                       11\n",
       "el-salvador-aid                            15\n",
       "religious-groups-in-schools                11\n",
       "anti-satellite-test-ban                    14\n",
       "aid-to-nicaraguan-contras                  15\n",
       "mx-missile                                 22\n",
       "immigration                                 7\n",
       "synfuels-corporation-cutback               21\n",
       "education-spending                         31\n",
       "superfund-right-to-sue                     25\n",
       "crime                                      17\n",
       "duty-free-exports                          28\n",
       "export-administration-act-south-africa    104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping NAs\n",
    "df_dropNA = df.dropna(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding - converting n/y to 0/1\n",
    "df_transformed = df_dropNA.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating columns for train test split\n",
    "#X = df_transformed.drop(columns=['Class Name'])\n",
    "#y = df_transformed[['Class Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the above statement throw an exception? Can you guess why? \n",
    "Check if the datatypes of X and y and see if they match that of cross_val_score signature.\n",
    "\n",
    "Hint: use type() function\n",
    "\n",
    "#### How do you change these dataframes to datatypes that'll fit your function signature?\n",
    "\n",
    "Hint: use .values and convert them to numpy array format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do a train test split. \n",
    "use https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html \n",
    "\n",
    "keep test_size=0.3 and set random state to 1 as your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 converting to numpy array\n",
    "X = np.array(df_transformed.drop(columns=['Class Name']).values)\n",
    "y = np.array(df_transformed['Class Name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of using train-test split, we'll cross-validate on the whole of X and y to maximize the scores\n",
    "\n",
    "Let's start with NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Classifier\n",
      "Precision: 0.89 (+/- 0.19)\n",
      "Recall: 0.95 (+/- 0.09)\n",
      "F1-score: 0.91 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive-Bayes Classifier\")\n",
    "nb = BernoulliNB()\n",
    "#scores = cross_val_score(nb, X, y, cv=5, scoring=scoring)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_val_score(nb, X, y, cv=5, scoring='precision').mean(), cross_val_score(nb, X, y, cv=5, scoring='precision').std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (cross_val_score(nb, X, y, cv=5, scoring='recall').mean(), cross_val_score(nb, X, y, cv=5, scoring='recall').std() * 2))\n",
    "print(\"F1-score: %0.2f (+/- %0.2f)\" % (cross_val_score(nb, X, y, cv=5, scoring='f1').mean(), cross_val_score(nb, X, y, cv=5, scoring='f1').std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Precision: 0.96 (+/- 0.11)\n",
      "Recall: 0.95 (+/- 0.09)\n",
      "F1-score: 0.95 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "#Repeat the same steps for DecisionTree Classifier\n",
    "print(\"Decision Tree Classifier\")\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_val_score(clf, X, y, cv=5, scoring='precision').mean(), cross_val_score(clf, X, y, cv=5, scoring='precision').std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (cross_val_score(clf, X, y, cv=5, scoring='recall').mean(), cross_val_score(clf, X, y, cv=5, scoring='recall').std() * 2))\n",
    "print(\"F1-score: %0.2f (+/- %0.2f)\" % (cross_val_score(clf, X, y, cv=5, scoring='f1').mean(), cross_val_score(clf, X, y, cv=5, scoring='f1').std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat for Treatment 2 and 3 and record scores for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treatment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling NA with m\n",
    "df_fillNewCat = df.fillna('m',inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_fillNewCat.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 converting to numpy array\n",
    "X = np.array(df_transformed.drop(columns=['Class Name']).values)\n",
    "y = np.array(df_transformed['Class Name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Classifier\n",
      "Precision: 0.64 (+/- 0.38)\n",
      "Recall: 0.09 (+/- 0.15)\n",
      "F1-score: 0.15 (+/- 0.19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive-Bayes Classifier\")\n",
    "nb = BernoulliNB()\n",
    "#scores = cross_val_score(nb, X, y, cv=5, scoring=scoring)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_val_score(nb, X, y, cv=5, scoring='precision').mean(), cross_val_score(nb, X, y, cv=5, scoring='precision').std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (cross_val_score(nb, X, y, cv=5, scoring='recall').mean(), cross_val_score(nb, X, y, cv=5, scoring='recall').std() * 2))\n",
    "print(\"F1-score: %0.2f (+/- %0.2f)\" % (cross_val_score(nb, X, y, cv=5, scoring='f1').mean(), cross_val_score(nb, X, y, cv=5, scoring='f1').std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Precision: 0.93 (+/- 0.10)\n",
      "Recall: 0.93 (+/- 0.10)\n",
      "F1-score: 0.93 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "#Repeat the same steps for DecisionTree Classifier\n",
    "print(\"Decision Tree Classifier\")\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_val_score(clf, X, y, cv=5, scoring='precision').mean(), cross_val_score(clf, X, y, cv=5, scoring='precision').std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (cross_val_score(clf, X, y, cv=5, scoring='recall').mean(), cross_val_score(clf, X, y, cv=5, scoring='recall').std() * 2))\n",
    "print(\"F1-score: %0.2f (+/- %0.2f)\" % (cross_val_score(clf, X, y, cv=5, scoring='f1').mean(), cross_val_score(clf, X, y, cv=5, scoring='f1').std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treatment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 17)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name                                  0\n",
       "handicapped-infants                        12\n",
       "water-project-cost-sharing                 48\n",
       "adoption-of-the-budget-resolution          11\n",
       "physician-fee-freeze                       11\n",
       "el-salvador-aid                            15\n",
       "religious-groups-in-schools                11\n",
       "anti-satellite-test-ban                    14\n",
       "aid-to-nicaraguan-contras                  15\n",
       "mx-missile                                 22\n",
       "immigration                                 7\n",
       "synfuels-corporation-cutback               21\n",
       "education-spending                         31\n",
       "superfund-right-to-sue                     25\n",
       "crime                                      17\n",
       "duty-free-exports                          28\n",
       "export-administration-act-south-africa    104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing NAs with most frequent\n",
    "df_fillMostFr = pd.DataFrame()\n",
    "for col in df.columns:\n",
    "    df_fillMostFr[col] = df[col].astype('category')\n",
    "    df_fillMostFr[col].fillna(df[col].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_fillMostFr.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_transformed.drop(columns=['Class Name']).values)\n",
    "y = np.array(df_transformed['Class Name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Classifier\n",
      "Precision: 0.85 (+/- 0.18)\n",
      "Recall: 0.92 (+/- 0.06)\n",
      "F1-score: 0.88 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive-Bayes Classifier\")\n",
    "nb = BernoulliNB()\n",
    "#scores = cross_val_score(nb, X, y, cv=5, scoring=scoring)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_val_score(nb, X, y, cv=5, scoring='precision').mean(), cross_val_score(nb, X, y, cv=5, scoring='precision').std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (cross_val_score(nb, X, y, cv=5, scoring='recall').mean(), cross_val_score(nb, X, y, cv=5, scoring='recall').std() * 2))\n",
    "print(\"F1-score: %0.2f (+/- %0.2f)\" % (cross_val_score(nb, X, y, cv=5, scoring='f1').mean(), cross_val_score(nb, X, y, cv=5, scoring='f1').std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Precision: 0.91 (+/- 0.07)\n",
      "Recall: 0.93 (+/- 0.09)\n",
      "F1-score: 0.93 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "#Repeat the same steps for DecisionTree Classifier\n",
    "print(\"Decision Tree Classifier\")\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_val_score(clf, X, y, cv=5, scoring='precision').mean(), cross_val_score(clf, X, y, cv=5, scoring='precision').std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (cross_val_score(clf, X, y, cv=5, scoring='recall').mean(), cross_val_score(clf, X, y, cv=5, scoring='recall').std() * 2))\n",
    "print(\"F1-score: %0.2f (+/- %0.2f)\" % (cross_val_score(clf, X, y, cv=5, scoring='f1').mean(), cross_val_score(clf, X, y, cv=5, scoring='f1').std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-67ea9c55",
   "language": "python",
   "display_name": "PyCharm (dsba6156)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}