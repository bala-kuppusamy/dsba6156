{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_classification_for_model(_model, _x_train, _x_test, _y_train, _y_test) -> None:\n",
    "    _model.fit(_x_train, _y_train)\n",
    "    _y_pred = _model.predict(_x_test)\n",
    "\n",
    "    print(\"Accuracy: %0.2f\" %accuracy_score(_y_test, _y_pred))\n",
    "    print(\"Precision: %0.2f\" %precision_score(_y_test, _y_pred, average=\"macro\"))\n",
    "    print(\"Recall:  %0.2f\" %recall_score(_y_test, _y_pred, average=\"macro\"))\n",
    "    print(\"F1-score:  %0.2f\" %f1_score(_y_test, _y_pred, average=\"macro\"))\n",
    "\n",
    "    print(confusion_matrix(_y_test, _y_pred))\n",
    "    print(classification_report(_y_test, _y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read training dataset from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(98855, 91)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "master: DataFrame = pd.read_pickle('./data/master-coded.pickle')\n",
    "print(master.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into x & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = master.drop('JobSatisfaction', axis=1)\n",
    "y = master[['JobSatisfaction']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 0.50\nPrecision: 0.33\n",
      "Recall:  0.33\n",
      "F1-score:  0.33\n[[ 144  183   98   74   91  148   67   14]\n [ 169  468  331  193  263  446  147   17]\n [ 103  303  380  238  383  658  231   31]\n [  59  176  255  243  317  469  123   23]\n [  79  297  415  308  612 1188  370   33]\n [ 180  523  722  445 1307 3725 1700  104]\n [  66  169  209  152  366 1647 1429   40]\n [  13   23   30   23   32   86   38 9447]]\n",
      "              precision    recall  f1-score   support\n\n           1       0.18      0.18      0.18       819\n           2       0.22      0.23      0.22      2034\n           3       0.16      0.16      0.16      2327\n           4       0.14      0.15      0.15      1665\n           5       0.18      0.19      0.18      3302\n           6       0.45      0.43      0.44      8706\n           7       0.35      0.35      0.35      4078\n           x       0.97      0.97      0.97      9692\n\n    accuracy                           0.50     32623\n   macro avg       0.33      0.33      0.33     32623\nweighted avg       0.51      0.50      0.51     32623\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_dt = tree.DecisionTreeClassifier()\n",
    "run_classification_for_model(model_dt, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 0.54\nPrecision: 0.40\n",
      "Recall:  0.37\nF1-score:  0.38\n[[ 157  231   72   43   45  132   36  103]\n [  99  601  333  107  147  423   93  231]\n [  40  218  510  159  244  748  118  290]\n [  15   90  275  251  234  477   66  257]\n [  19   99  356  165  564 1513  201  385]\n [  31  138  304  201  721 4866 1464  981]\n [  23   46   30   39  108 1475 1949  408]\n [  92   90   70  322  105  207  147 8659]]\n",
      "              precision    recall  f1-score   support\n\n           1       0.33      0.19      0.24       819\n           2       0.40      0.30      0.34      2034\n           3       0.26      0.22      0.24      2327\n           4       0.20      0.15      0.17      1665\n           5       0.26      0.17      0.21      3302\n           6       0.49      0.56      0.52      8706\n           7       0.48      0.48      0.48      4078\n           x       0.77      0.89      0.82      9692\n\n    accuracy                           0.54     32623\n   macro avg       0.40      0.37      0.38     32623\nweighted avg       0.51      0.54      0.52     32623\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_nb = BernoulliNB()\n",
    "run_classification_for_model(model_nb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 0.56\nPrecision: 0.39\n",
      "Recall:  0.37\nF1-score:  0.38\n",
      "[[ 180  240   75   31   74  176   32   11]\n [ 178  647  285  116  197  520   75   16]\n [  83  374  377  166  361  811  132   23]\n [  34  186  246  218  282  610   65   24]\n [  38  254  315  217  609 1640  213   16]\n [  66  324  404  274  926 5377 1277   58]\n [  31   71   75   61  169 2190 1455   26]\n [  11   18   15   20   32  100   31 9465]]\n",
      "              precision    recall  f1-score   support\n\n           1       0.29      0.22      0.25       819\n           2       0.31      0.32      0.31      2034\n           3       0.21      0.16      0.18      2327\n           4       0.20      0.13      0.16      1665\n           5       0.23      0.18      0.20      3302\n           6       0.47      0.62      0.53      8706\n           7       0.44      0.36      0.40      4078\n           x       0.98      0.98      0.98      9692\n\n    accuracy                           0.56     32623\n   macro avg       0.39      0.37      0.38     32623\nweighted avg       0.55      0.56      0.55     32623\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_jobs=10, random_state=0)\n",
    "run_classification_for_model(model_rf, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 0.30\nPrecision: 0.06\n",
      "Recall:  0.12\n",
      "F1-score:  0.06\n[[   0    0    0    0    0    1    0  818]\n [   0    0    0    0    0    2    0 2032]\n [   0    0    0    0    0    1    0 2326]\n [   0    0    0    0    0    6    0 1659]\n [   0    0    0    0    0    3    0 3299]\n [   0    0    0    0    0   16    0 8690]\n [   0    0    0    0    0    9    0 4069]\n [   0    0    0    0    0   54    0 9638]]\n",
      "              precision    recall  f1-score   support\n\n           1       0.00      0.00      0.00       819\n           2       0.00      0.00      0.00      2034\n           3       0.00      0.00      0.00      2327\n           4       0.00      0.00      0.00      1665\n           5       0.00      0.00      0.00      3302\n           6       0.17      0.00      0.00      8706\n           7       0.00      0.00      0.00      4078\n           x       0.30      0.99      0.46      9692\n\n    accuracy                           0.30     32623\n   macro avg       0.06      0.12      0.06     32623\nweighted avg       0.13      0.30      0.14     32623\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "run_classification_for_model(model_lr, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read training dataset - #2 from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(98855, 95)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "master_2: DataFrame = pd.read_pickle('./data/master-coded-2.pickle')\n",
    "print(master_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset - #2 into x & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X2 = master_2.drop('AIFuture', axis=1)\n",
    "y2 = master_2[['AIFuture']]\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree classifier - #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 0.69\nPrecision: 0.50\n",
      "Recall:  0.50\n",
      "F1-score:  0.50\n[[12012  1373  3166   198]\n [ 1265   197   384    68]\n [ 2875   364  1059    96]\n [  236    70   101  9159]]\n",
      "              precision    recall  f1-score   support\n\n     EXCITED       0.73      0.72      0.72     16749\n NO-COMMENTS       0.10      0.10      0.10      1914\n     WORRIED       0.22      0.24      0.23      4394\n           x       0.96      0.96      0.96      9566\n\n    accuracy                           0.69     32623\n   macro avg       0.50      0.50      0.50     32623\nweighted avg       0.69      0.69      0.69     32623\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_dt_2 = tree.DecisionTreeClassifier()\n",
    "run_classification_for_model(model_dt_2, X2_train, X2_test, y2_train, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classification - #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 0.78\nPrecision: 0.59\n",
      "Recall:  0.50\nF1-score:  0.49\n",
      "[[16115   114   213   307]\n [ 1678   106    62    68]\n [ 4002    67   211   114]\n [  301   134    21  9110]]\n",
      "              precision    recall  f1-score   support\n\n     EXCITED       0.73      0.96      0.83     16749\n NO-COMMENTS       0.25      0.06      0.09      1914\n     WORRIED       0.42      0.05      0.09      4394\n           x       0.95      0.95      0.95      9566\n\n    accuracy                           0.78     32623\n   macro avg       0.59      0.50      0.49     32623\nweighted avg       0.72      0.78      0.72     32623\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_nb_2 = BernoulliNB()\n",
    "run_classification_for_model(model_nb_2, X2_train, X2_test, y2_train, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 0.79\nPrecision: 0.56\n",
      "Recall:  0.50\n",
      "F1-score:  0.49\n[[16056    71   502   120]\n [ 1713    38   102    61]\n [ 4017    39   279    59]\n [  267     8    19  9272]]\n",
      "              precision    recall  f1-score   support\n\n     EXCITED       0.73      0.96      0.83     16749\n NO-COMMENTS       0.24      0.02      0.04      1914\n     WORRIED       0.31      0.06      0.11      4394\n           x       0.97      0.97      0.97      9566\n\n    accuracy                           0.79     32623\n   macro avg       0.56      0.50      0.49     32623\nweighted avg       0.72      0.79      0.73     32623\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_rf_2 = RandomForestClassifier(n_jobs=10, random_state=0)\n",
    "run_classification_for_model(model_rf_2, X2_train, X2_test, y2_train, y2_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 0.78\nPrecision: 0.41\n",
      "Recall:  0.49\n",
      "F1-score:  0.44\n[[16245     0     0   504]\n [ 1716     0     0   198]\n [ 4101     0     0   293]\n [  218     0     0  9348]]\n",
      "              precision    recall  f1-score   support\n\n     EXCITED       0.73      0.97      0.83     16749\n NO-COMMENTS       0.00      0.00      0.00      1914\n     WORRIED       0.00      0.00      0.00      4394\n           x       0.90      0.98      0.94      9566\n\n    accuracy                           0.78     32623\n   macro avg       0.41      0.49      0.44     32623\nweighted avg       0.64      0.78      0.70     32623\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_lr_2 = LogisticRegression()\n",
    "run_classification_for_model(model_lr_2, X2_train, X2_test, y2_train, y2_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (dsba6156)",
   "language": "python",
   "name": "pycharm-67ea9c55"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}